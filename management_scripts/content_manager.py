#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é»„åœŸé«˜åŸæ¡ˆä¾‹åº“å†…å®¹ç®¡ç†è„šæœ¬
åŠŸèƒ½ï¼šæ‰¹é‡æ·»åŠ æ¡ˆä¾‹ã€å¯¼å…¥æ•°æ®ã€å†…å®¹éªŒè¯ã€SEOä¼˜åŒ–

ä½¿ç”¨æ–¹æ³•ï¼š
python content_manager.py --help
"""

import os
import sys
import json
import csv
import argparse
import requests
import uuid
from datetime import datetime
from typing import Dict, List, Optional
import re
from pathlib import Path

class ContentManager:
    def __init__(self, supabase_url: str = "", supabase_key: str = ""):
        self.supabase_url = supabase_url
        self.supabase_key = supabase_key
        self.headers = {
            'apikey': supabase_key,
            'Authorization': f'Bearer {supabase_key}',
            'Content-Type': 'application/json'
        }
    
    def load_env_config(self):
        """ä»ç¯å¢ƒæ–‡ä»¶åŠ è½½é…ç½®"""
        env_file = '.env.local'
        if os.path.exists(env_file):
            with open(env_file, 'r') as f:
                for line in f:
                    if '=' in line and not line.startswith('#'):
                        key, value = line.strip().split('=', 1)
                        if key == 'VITE_SUPABASE_URL':
                            self.supabase_url = value
                        elif key == 'VITE_SUPABASE_ANON_KEY':
                            self.supabase_key = value
            
            self.headers = {
                'apikey': self.supabase_key,
                'Authorization': f'Bearer {self.supabase_key}',
                'Content-Type': 'application/json'
            }
    
    def validate_case_data(self, case_data: Dict) -> List[str]:
        """éªŒè¯æ¡ˆä¾‹æ•°æ®å®Œæ•´æ€§"""
        errors = []
        required_fields = ['title', 'description', 'category_id', 'status']
        
        for field in required_fields:
            if not case_data.get(field):
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # éªŒè¯æ ‡é¢˜é•¿åº¦
        if case_data.get('title') and len(case_data['title']) > 200:
            errors.append("æ ‡é¢˜é•¿åº¦ä¸èƒ½è¶…è¿‡200å­—ç¬¦")
        
        # éªŒè¯çŠ¶æ€å€¼
        valid_statuses = ['draft', 'review', 'published', 'archived']
        if case_data.get('status') not in valid_statuses:
            errors.append(f"çŠ¶æ€å€¼æ— æ•ˆï¼Œå¿…é¡»æ˜¯: {', '.join(valid_statuses)}")
        
        # éªŒè¯åˆ†ç±»ID
        if case_data.get('category_id') and not isinstance(case_data['category_id'], int):
            errors.append("category_idå¿…é¡»æ˜¯æ•´æ•°")
        
        return errors
    
    def optimize_content_for_seo(self, case_data: Dict) -> Dict:
        """ä¼˜åŒ–å†…å®¹ä»¥æé«˜SEO"""
        optimized = case_data.copy()
        
        # ç”ŸæˆSEOå‹å¥½çš„slug
        if 'title' in optimized:
            slug = self.generate_slug(optimized['title'])
            optimized['slug'] = slug
        
        # ç¡®ä¿descriptioné•¿åº¦é€‚ä¸­ï¼ˆ150-160å­—ç¬¦æœ€ä½³ï¼‰
        if 'description' in optimized:
            desc = optimized['description']
            if len(desc) > 160:
                optimized['meta_description'] = desc[:157] + '...'\n            else:\n                optimized['meta_description'] = desc
        
        # æå–å…³é”®è¯ä½œä¸ºtags
        if 'content' in optimized and 'tags' not in optimized:
            keywords = self.extract_keywords(optimized['content'])\n            optimized['tags'] = keywords[:5]  # é™åˆ¶æœ€å¤š5ä¸ªæ ‡ç­¾
        
        return optimized
    
    def generate_slug(self, title: str) -> str:
        \"\"\"ç”ŸæˆURLå‹å¥½çš„slug\"\"\"
        # è½¬æ¢ä¸ºå°å†™å¹¶æ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦
        slug = re.sub(r'[^\\w\\s-]', '', title.lower())
        slug = re.sub(r'[-\\s]+', '-', slug)
        return slug.strip('-')
    
    def extract_keywords(self, content: str) -> List[str]:
        \"\"\"ä»å†…å®¹ä¸­æå–å…³é”®è¯\"\"\"
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå¯ä»¥ç”¨æ›´å¤æ‚çš„NLPæ–¹æ³•ï¼‰
        keywords = []
        
        # å®šä¹‰ç”Ÿæ€ç›¸å…³çš„å…³é”®è¯
        eco_keywords = [
            'æ°´åœŸä¿æŒ', 'ç”Ÿæ€æ²»ç†', 'æ¤è¢«æ¢å¤', 'æ¢¯ç”°', 'æ·¤åœ°å',
            'é»„åœŸé«˜åŸ', 'æ°´åœŸæµå¤±', 'ç”Ÿæ€æ–‡æ˜', 'ç»¿åŒ–', 'é€ æ—',
            'å¡é¢æ²»ç†', 'æ²Ÿé“æ²»ç†', 'å°æµåŸŸ', 'ç»¼åˆæ²»ç†', 'é€€è€•è¿˜æ—'
        ]
        
        content_lower = content.lower()
        for keyword in eco_keywords:
            if keyword in content:
                keywords.append(keyword)
        
        return keywords
    
    def create_case(self, case_data: Dict) -> Optional[str]:
        \"\"\"åˆ›å»ºæ–°æ¡ˆä¾‹\"\"\"
        # éªŒè¯æ•°æ®
        errors = self.validate_case_data(case_data)
        if errors:
            print(f\"âŒ æ•°æ®éªŒè¯å¤±è´¥: {', '.join(errors)}\")
            return None
        
        # SEOä¼˜åŒ–
        optimized_data = self.optimize_content_for_seo(case_data)
        
        # æ·»åŠ åˆ›å»ºæ—¶é—´å’ŒID
        optimized_data.update({
            'id': str(uuid.uuid4()),
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        })
        
        try:
            response = requests.post(
                f\"{self.supabase_url}/rest/v1/cases\",
                json=optimized_data,
                headers=self.headers
            )
            
            if response.status_code == 201:
                case_id = response.json()[0]['id']
                print(f\"âœ… æ¡ˆä¾‹åˆ›å»ºæˆåŠŸ: {case_id}\")
                return case_id
            else:
                print(f\"âŒ åˆ›å»ºå¤±è´¥: {response.text}\")
                return None
                
        except Exception as e:
            print(f\"âŒ åˆ›å»ºå¼‚å¸¸: {e}\")
            return None
    
    def batch_import_from_csv(self, csv_file: str) -> Dict:
        \"\"\"ä»CSVæ–‡ä»¶æ‰¹é‡å¯¼å…¥æ¡ˆä¾‹\"\"\"
        results = {'success': 0, 'failed': 0, 'errors': []}
        
        try:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                for row_num, row in enumerate(reader, 1):
                    # è½¬æ¢å­—ç¬¦ä¸²ä¸ºé€‚å½“çš„æ•°æ®ç±»å‹
                    processed_row = self.process_csv_row(row)
                    
                    case_id = self.create_case(processed_row)
                    if case_id:
                        results['success'] += 1
                        print(f\"ç¬¬{row_num}è¡Œ: æˆåŠŸåˆ›å»ºæ¡ˆä¾‹ {processed_row.get('title', '')}\")
                    else:
                        results['failed'] += 1
                        results['errors'].append(f\"ç¬¬{row_num}è¡Œ: {processed_row.get('title', '')}\")
        
        except FileNotFoundError:
            print(f\"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {csv_file}\")
        except Exception as e:
            print(f\"âŒ å¯¼å…¥å¼‚å¸¸: {e}\")
        
        return results
    
    def process_csv_row(self, row: Dict) -> Dict:
        \"\"\"å¤„ç†CSVè¡Œæ•°æ®\"\"\"
        processed = {}
        
        # å­—æ®µæ˜ å°„
        field_mapping = {
            'title': 'title',
            'description': 'description', 
            'content': 'content',
            'category_id': 'category_id',
            'region': 'region',
            'status': 'status',
            'tags': 'tags',
            'summary': 'summary',
            'subtitle': 'subtitle'
        }
        
        for csv_field, db_field in field_mapping.items():
            if csv_field in row and row[csv_field]:
                value = row[csv_field].strip()
                
                # ç‰¹æ®Šå¤„ç†
                if db_field == 'category_id':
                    processed[db_field] = int(value) if value.isdigit() else 1
                elif db_field == 'tags':
                    # å¤„ç†æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰
                    processed[db_field] = [tag.strip() for tag in value.split(',') if tag.strip()]
                elif db_field == 'status':
                    processed[db_field] = value if value in ['draft', 'review', 'published', 'archived'] else 'draft'
                else:
                    processed[db_field] = value
        
        return processed
    
    def export_cases_to_csv(self, output_file: str, status: str = 'published') -> bool:
        \"\"\"å¯¼å‡ºæ¡ˆä¾‹åˆ°CSVæ–‡ä»¶\"\"\"
        try:
            # è·å–æ¡ˆä¾‹æ•°æ®
            url = f\"{self.supabase_url}/rest/v1/cases\"
            params = {'status': f'eq.{status}'}
            
            response = requests.get(url, headers=self.headers, params=params)
            
            if response.status_code != 200:
                print(f\"âŒ è·å–æ•°æ®å¤±è´¥: {response.text}\")
                return False
            
            cases = response.json()
            
            if not cases:
                print(\"âš ï¸ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ¡ˆä¾‹\")
                return False
            
            # å†™å…¥CSVæ–‡ä»¶
            with open(output_file, 'w', newline='', encoding='utf-8') as f:
                fieldnames = ['id', 'title', 'description', 'content', 'category_id', 
                             'region', 'status', 'tags', 'view_count', 'like_count',
                             'created_at', 'updated_at']
                
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for case in cases:
                    # å¤„ç†æ•°ç»„å­—æ®µ
                    row = case.copy()
                    if 'tags' in row and isinstance(row['tags'], list):
                        row['tags'] = ', '.join(row['tags'])
                    
                    writer.writerow(row)
            
            print(f\"âœ… å·²å¯¼å‡º {len(cases)} ä¸ªæ¡ˆä¾‹åˆ° {output_file}\")
            return True
            
        except Exception as e:
            print(f\"âŒ å¯¼å‡ºå¼‚å¸¸: {e}\")
            return False
    
    def update_case_images(self, case_id: str, image_urls: List[str]) -> bool:
        \"\"\"æ›´æ–°æ¡ˆä¾‹å›¾ç‰‡\"\"\"
        try:
            # æ„å»ºå›¾ç‰‡æ•°æ®
            media_data = []
            for i, url in enumerate(image_urls):
                media_data.append({
                    'case_id': case_id,
                    'file_type': 'image',
                    'file_url': url,
                    'file_name': f'image_{i+1}',
                    'sort_order': i
                })
            
            # å…ˆåˆ é™¤ç°æœ‰å›¾ç‰‡
            delete_response = requests.delete(
                f\"{self.supabase_url}/rest/v1/media_files\",
                headers=self.headers,
                params={'case_id': f'eq.{case_id}', 'file_type': 'eq.image'}
            )
            
            # æ·»åŠ æ–°å›¾ç‰‡
            if media_data:
                response = requests.post(
                    f\"{self.supabase_url}/rest/v1/media_files\",
                    json=media_data,
                    headers=self.headers
                )
                
                if response.status_code == 201:
                    print(f\"âœ… å·²æ›´æ–°æ¡ˆä¾‹ {case_id} çš„ {len(image_urls)} å¼ å›¾ç‰‡\")
                    return True
                else:
                    print(f\"âŒ æ›´æ–°å›¾ç‰‡å¤±è´¥: {response.text}\")
                    return False
            
            return True
            
        except Exception as e:
            print(f\"âŒ æ›´æ–°å›¾ç‰‡å¼‚å¸¸: {e}\")
            return False
    
    def generate_content_report(self) -> Dict:
        \"\"\"ç”Ÿæˆå†…å®¹åˆ†ææŠ¥å‘Š\"\"\"
        try:
            # è·å–ç»Ÿè®¡æ•°æ®
            cases_response = requests.get(
                f\"{self.supabase_url}/rest/v1/cases\",
                headers=self.headers,
                params={'select': 'status,category_id,view_count,like_count,created_at'}
            )
            
            categories_response = requests.get(
                f\"{self.supabase_url}/rest/v1/categories\",
                headers=self.headers
            )
            
            if cases_response.status_code != 200 or categories_response.status_code != 200:
                print(\"âŒ è·å–æ•°æ®å¤±è´¥\")
                return {}
            
            cases = cases_response.json()
            categories = {cat['id']: cat['name'] for cat in categories_response.json()}
            
            # åˆ†ææ•°æ®
            report = {
                'total_cases': len(cases),
                'status_distribution': {},
                'category_distribution': {},
                'engagement_stats': {
                    'total_views': sum(case.get('view_count', 0) for case in cases),
                    'total_likes': sum(case.get('like_count', 0) for case in cases),
                    'avg_views': 0,
                    'avg_likes': 0
                },
                'recent_activity': {}
            }
            
            # çŠ¶æ€åˆ†å¸ƒ
            for case in cases:
                status = case.get('status', 'unknown')
                report['status_distribution'][status] = report['status_distribution'].get(status, 0) + 1
            
            # åˆ†ç±»åˆ†å¸ƒ
            for case in cases:
                cat_id = case.get('category_id')
                cat_name = categories.get(cat_id, 'Unknown')
                report['category_distribution'][cat_name] = report['category_distribution'].get(cat_name, 0) + 1
            
            # å‚ä¸åº¦ç»Ÿè®¡
            if cases:
                report['engagement_stats']['avg_views'] = report['engagement_stats']['total_views'] / len(cases)
                report['engagement_stats']['avg_likes'] = report['engagement_stats']['total_likes'] / len(cases)
            
            # æœ€è¿‘æ´»åŠ¨ï¼ˆæŒ‰æœˆç»Ÿè®¡ï¼‰
            from collections import defaultdict
            monthly_counts = defaultdict(int)
            for case in cases:
                if case.get('created_at'):
                    month = case['created_at'][:7]  # YYYY-MM
                    monthly_counts[month] += 1
            
            report['recent_activity'] = dict(sorted(monthly_counts.items(), reverse=True)[:12])
            
            return report
            
        except Exception as e:
            print(f\"âŒ ç”ŸæˆæŠ¥å‘Šå¼‚å¸¸: {e}\")
            return {}
    
    def print_content_report(self, report: Dict):
        \"\"\"æ‰“å°å†…å®¹åˆ†ææŠ¥å‘Š\"\"\"
        if not report:
            return
        
        print(\"\\nğŸ“Š å†…å®¹åˆ†ææŠ¥å‘Š\")
        print(\"=\" * 50)
        
        print(f\"ğŸ“š æ€»æ¡ˆä¾‹æ•°: {report['total_cases']}\")
        print(f\"ğŸ‘ æ€»æµè§ˆé‡: {report['engagement_stats']['total_views']:,}\")
        print(f\"â¤ï¸ æ€»ç‚¹èµæ•°: {report['engagement_stats']['total_likes']:,}\")
        print(f\"ğŸ“Š å¹³å‡æµè§ˆé‡: {report['engagement_stats']['avg_views']:.1f}\")
        print(f\"ğŸ“Š å¹³å‡ç‚¹èµæ•°: {report['engagement_stats']['avg_likes']:.1f}\")
        
        print(\"\\nğŸ“‹ çŠ¶æ€åˆ†å¸ƒ:\")
        for status, count in report['status_distribution'].items():
            percentage = (count / report['total_cases']) * 100
            print(f\"   {status}: {count} ({percentage:.1f}%)\")
        
        print(\"\\nğŸ“‚ åˆ†ç±»åˆ†å¸ƒ:\")
        for category, count in report['category_distribution'].items():
            percentage = (count / report['total_cases']) * 100
            print(f\"   {category}: {count} ({percentage:.1f}%)\")
        
        print(\"\\nğŸ“… æœ€è¿‘12ä¸ªæœˆæ–°å¢æ¡ˆä¾‹:\")
        for month, count in list(report['recent_activity'].items())[:6]:
            print(f\"   {month}: {count} ä¸ª\")

def main():
    parser = argparse.ArgumentParser(description='é»„åœŸé«˜åŸæ¡ˆä¾‹åº“å†…å®¹ç®¡ç†å·¥å…·')
    parser.add_argument('--create', help='åˆ›å»ºå•ä¸ªæ¡ˆä¾‹ (JSONæ–‡ä»¶è·¯å¾„)')
    parser.add_argument('--import-csv', help='ä»CSVæ–‡ä»¶æ‰¹é‡å¯¼å…¥æ¡ˆä¾‹')
    parser.add_argument('--export-csv', help='å¯¼å‡ºæ¡ˆä¾‹åˆ°CSVæ–‡ä»¶')
    parser.add_argument('--status', default='published', help='å¯¼å‡ºæ—¶çš„æ¡ˆä¾‹çŠ¶æ€ç­›é€‰')
    parser.add_argument('--report', action='store_true', help='ç”Ÿæˆå†…å®¹åˆ†ææŠ¥å‘Š')
    parser.add_argument('--template', action='store_true', help='ç”ŸæˆCSVå¯¼å…¥æ¨¡æ¿')
    parser.add_argument('--update-images', help='æ›´æ–°æ¡ˆä¾‹å›¾ç‰‡ (æ ¼å¼: case_id,url1,url2,...)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå†…å®¹ç®¡ç†å™¨
    manager = ContentManager()
    manager.load_env_config()
    
    if not manager.supabase_url or not manager.supabase_key:
        print(\"âŒ é”™è¯¯: æœªé…ç½®Supabaseè¿æ¥ä¿¡æ¯\")
        print(\"è¯·ç¡®ä¿.env.localæ–‡ä»¶ä¸­åŒ…å«VITE_SUPABASE_URLå’ŒVITE_SUPABASE_ANON_KEY\")
        return
    
    if args.create:
        # åˆ›å»ºå•ä¸ªæ¡ˆä¾‹
        try:
            with open(args.create, 'r', encoding='utf-8') as f:
                case_data = json.load(f)
            manager.create_case(case_data)
        except FileNotFoundError:
            print(f\"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {args.create}\")
        except json.JSONDecodeError:
            print(f\"âŒ JSONæ ¼å¼é”™è¯¯: {args.create}\")
    
    elif args.import_csv:
        # æ‰¹é‡å¯¼å…¥
        results = manager.batch_import_from_csv(args.import_csv)
        print(f\"\\nğŸ“Š å¯¼å…¥ç»“æœ: æˆåŠŸ {results['success']} ä¸ª, å¤±è´¥ {results['failed']} ä¸ª\")
        if results['errors']:
            print(\"âŒ å¤±è´¥çš„è®°å½•:\")
            for error in results['errors']:
                print(f\"   {error}\")
    
    elif args.export_csv:
        # å¯¼å‡ºæ¡ˆä¾‹
        manager.export_cases_to_csv(args.export_csv, args.status)
    
    elif args.report:
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = manager.generate_content_report()
        manager.print_content_report(report)
    
    elif args.template:
        # ç”ŸæˆCSVæ¨¡æ¿
        template_file = 'case_import_template.csv'
        fieldnames = ['title', 'description', 'content', 'category_id', 'region', 
                     'status', 'tags', 'summary', 'subtitle']
        
        with open(template_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            # æ·»åŠ ç¤ºä¾‹è¡Œ
            writer.writerow({
                'title': 'ç¤ºä¾‹æ¡ˆä¾‹ï¼šé«˜è¥¿æ²ŸæµåŸŸç»¼åˆæ²»ç†',
                'description': 'é™•è¥¿çœç±³è„‚å¿é«˜è¥¿æ²ŸæµåŸŸæ°´åœŸä¿æŒç»¼åˆæ²»ç†çš„æˆåŠŸå®è·µ',
                'content': 'è¯¦ç»†çš„æ¡ˆä¾‹å†…å®¹ï¼ŒåŒ…æ‹¬æ²»ç†æªæ–½ã€æŠ€æœ¯æ–¹æ¡ˆã€å®æ–½è¿‡ç¨‹ç­‰...',
                'category_id': '1',
                'region': 'é™•è¥¿çœç±³è„‚å¿',
                'status': 'published',
                'tags': 'æ°´åœŸä¿æŒ,æµåŸŸæ²»ç†,ç»¼åˆæ²»ç†',
                'summary': 'é€šè¿‡ç»¼åˆæ²»ç†æªæ–½ï¼Œå®ç°äº†æ°´åœŸä¿æŒå’Œç”Ÿæ€æ¢å¤çš„åŒé‡ç›®æ ‡',
                'subtitle': 'æµåŸŸç»¼åˆæ²»ç†çš„å…¸å‹æ¡ˆä¾‹'
            })
        
        print(f\"âœ… CSVå¯¼å…¥æ¨¡æ¿å·²ç”Ÿæˆ: {template_file}\")
    
    elif args.update_images:
        # æ›´æ–°æ¡ˆä¾‹å›¾ç‰‡
        parts = args.update_images.split(',')
        if len(parts) >= 2:
            case_id = parts[0]
            image_urls = parts[1:]
            manager.update_case_images(case_id, image_urls)
        else:
            print(\"âŒ æ ¼å¼é”™è¯¯ï¼Œæ­£ç¡®æ ¼å¼: case_id,url1,url2,...\")
    
    else:
        parser.print_help()

if __name__ == \"__main__\":
    main()
