#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é»„åœŸé«˜åŸæ¡ˆä¾‹åº“æ•°æ®åº“ç®¡ç†å·¥å…·
åŠŸèƒ½ï¼šæ•°æ®å¤‡ä»½ã€æ¢å¤ã€åˆå§‹åŒ–ã€ç»Ÿè®¡åˆ†æ

ä½¿ç”¨æ–¹æ³•ï¼š
python database_tools.py --help
"""

import os
import sys
import json
import argparse
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Optional

# æ•°æ®åº“è¿æ¥é…ç½®
DB_CONFIG = {
    'host': 'db.your-project.supabase.co',
    'port': '5432',
    'database': 'postgres',
    'user': 'postgres',
    'password': 'your-database-password'
}

# SQLæŸ¥è¯¢æ¨¡æ¿
QUERIES = {
    'site_stats': """
        SELECT 
            (SELECT COUNT(*) FROM cases WHERE status = 'published') as total_cases,
            (SELECT COUNT(*) FROM categories WHERE is_active = true) as total_categories,
            (SELECT COUNT(*) FROM users WHERE is_active = true) as total_users,
            (SELECT SUM(view_count) FROM cases) as total_views,
            (SELECT COUNT(*) FROM access_logs WHERE created_at > NOW() - INTERVAL '30 days') as monthly_visits;
    """,
    
    'popular_cases': """
        SELECT 
            c.title,
            c.view_count,
            c.like_count,
            cat.name as category_name,
            c.created_at
        FROM cases c
        LEFT JOIN categories cat ON c.category_id = cat.id
        WHERE c.status = 'published'
        ORDER BY c.view_count DESC
        LIMIT 10;
    """,
    
    'user_activity': """
        SELECT 
            DATE(created_at) as date,
            COUNT(*) as total_actions,
            COUNT(DISTINCT user_id) as unique_users,
            COUNT(CASE WHEN action = 'view' THEN 1 END) as views,
            COUNT(CASE WHEN action = 'download' THEN 1 END) as downloads
        FROM access_logs
        WHERE created_at > NOW() - INTERVAL '7 days'
        GROUP BY DATE(created_at)
        ORDER BY date DESC;
    """,
    
    'ai_usage_stats': """
        SELECT 
            generation_type,
            model,
            COUNT(*) as usage_count,
            SUM(tokens_used) as total_tokens,
            SUM(cost_cents) / 100.0 as total_cost_usd,
            AVG(cost_cents) / 100.0 as avg_cost_usd
        FROM ai_generations
        WHERE created_at > NOW() - INTERVAL '30 days'
        GROUP BY generation_type, model
        ORDER BY usage_count DESC;
    """
}

class DatabaseManager:
    def __init__(self, config: Dict[str, str]):
        self.config = config
        self.connection_string = f"postgresql://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}"
    
    def execute_query(self, query: str) -> List[Dict]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶è¿”å›ç»“æœ"""
        try:
            import psycopg2
            import psycopg2.extras
            
            conn = psycopg2.connect(
                host=self.config['host'],
                port=self.config['port'],
                database=self.config['database'],
                user=self.config['user'],
                password=self.config['password']
            )
            
            with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cursor:
                cursor.execute(query)
                results = cursor.fetchall()
                return [dict(row) for row in results]
                
        except ImportError:
            print("âŒ é”™è¯¯: è¯·å®‰è£…psycopg2-binaryåº“")
            print("è¿è¡Œ: pip install psycopg2-binary")
            return []
        except Exception as e:
            print(f"âŒ æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {e}")
            return []
        finally:
            if 'conn' in locals():
                conn.close()
    
    def get_site_statistics(self) -> Dict:
        """è·å–ç½‘ç«™ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“Š è·å–ç½‘ç«™ç»Ÿè®¡ä¿¡æ¯...")
        results = self.execute_query(QUERIES['site_stats'])
        if results:
            stats = results[0]
            print("\n=== ç½‘ç«™ç»Ÿè®¡ä¿¡æ¯ ===")
            print(f"ğŸ“š å‘å¸ƒæ¡ˆä¾‹æ•°: {stats['total_cases']}")
            print(f"ğŸ“‚ æ´»è·ƒåˆ†ç±»æ•°: {stats['total_categories']}")
            print(f"ğŸ‘¥ æ´»è·ƒç”¨æˆ·æ•°: {stats['total_users']}")
            print(f"ğŸ‘ æ€»æµè§ˆé‡: {stats['total_views']}")
            print(f"ğŸ“ˆ æœˆåº¦è®¿é—®: {stats['monthly_visits']}")
            return stats
        return {}
    
    def get_popular_cases(self) -> List[Dict]:
        """è·å–çƒ­é—¨æ¡ˆä¾‹"""
        print("ğŸ”¥ è·å–çƒ­é—¨æ¡ˆä¾‹...")
        results = self.execute_query(QUERIES['popular_cases'])
        if results:
            print("\n=== çƒ­é—¨æ¡ˆä¾‹æ’è¡Œ ===")
            for i, case in enumerate(results, 1):
                print(f"{i:2d}. {case['title'][:30]:<30} | æµè§ˆ: {case['view_count']:>5} | åˆ†ç±»: {case['category_name']}")
        return results
    
    def get_user_activity(self) -> List[Dict]:
        """è·å–ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡"""
        print("ğŸ“ˆ è·å–ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡...")
        results = self.execute_query(QUERIES['user_activity'])
        if results:
            print("\n=== è¿‘7å¤©ç”¨æˆ·æ´»åŠ¨ ===")
            print("æ—¥æœŸ       | æ€»æ“ä½œ | ç‹¬ç«‹ç”¨æˆ· | æµè§ˆé‡ | ä¸‹è½½é‡")
            print("-" * 50)
            for activity in results:
                print(f"{activity['date']} | {activity['total_actions']:>6} | {activity['unique_users']:>8} | {activity['views']:>6} | {activity['downloads']:>6}")
        return results
    
    def get_ai_usage_stats(self) -> List[Dict]:
        """è·å–AIä½¿ç”¨ç»Ÿè®¡"""
        print("ğŸ¤– è·å–AIä½¿ç”¨ç»Ÿè®¡...")
        results = self.execute_query(QUERIES['ai_usage_stats'])
        if results:
            print("\n=== AIåŠŸèƒ½ä½¿ç”¨ç»Ÿè®¡ï¼ˆè¿‘30å¤©ï¼‰ ===")
            print("ç±»å‹          | æ¨¡å‹        | ä½¿ç”¨æ¬¡æ•° | æ€»Token | æ€»æˆæœ¬($) | å¹³å‡æˆæœ¬($)")
            print("-" * 75)
            for stat in results:
                print(f"{stat['generation_type']:<12} | {stat['model']:<10} | {stat['usage_count']:>8} | {stat['total_tokens']:>7} | {stat['total_cost_usd']:>9.2f} | {stat['avg_cost_usd']:>11.3f}")
        return results
    
    def backup_database(self, backup_dir: str = "backups") -> str:
        """å¤‡ä»½æ•°æ®åº“"""
        print("ğŸ’¾ å¼€å§‹æ•°æ®åº“å¤‡ä»½...")
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = os.path.join(backup_dir, f"database_backup_{timestamp}.sql")
        
        # æ‰§è¡Œpg_dumpå‘½ä»¤
        try:
            cmd = [
                "pg_dump",
                "--host", self.config['host'],
                "--port", self.config['port'],
                "--username", self.config['user'],
                "--dbname", self.config['database'],
                "--no-password",
                "--verbose",
                "--file", backup_file
            ]
            
            # è®¾ç½®å¯†ç ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env['PGPASSWORD'] = self.config['password']
            
            result = subprocess.run(cmd, env=env, capture_output=True, text=True)
            
            if result.returncode == 0:
                file_size = os.path.getsize(backup_file) / (1024 * 1024)  # MB
                print(f"âœ… å¤‡ä»½æˆåŠŸ: {backup_file} ({file_size:.2f} MB)")
                return backup_file
            else:
                print(f"âŒ å¤‡ä»½å¤±è´¥: {result.stderr}")
                return ""
                
        except FileNotFoundError:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ°pg_dumpå‘½ä»¤ï¼Œè¯·ç¡®ä¿PostgreSQLå®¢æˆ·ç«¯å·¥å…·å·²å®‰è£…")
            return ""
        except Exception as e:
            print(f"âŒ å¤‡ä»½é”™è¯¯: {e}")
            return ""
    
    def clean_old_logs(self, days: int = 30) -> int:
        """æ¸…ç†æ—§çš„è®¿é—®æ—¥å¿—"""
        print(f"ğŸ§¹ æ¸…ç†{days}å¤©å‰çš„è®¿é—®æ—¥å¿—...")
        
        query = f"""
        DELETE FROM access_logs 
        WHERE created_at < NOW() - INTERVAL '{days} days';
        """
        
        try:
            import psycopg2
            
            conn = psycopg2.connect(
                host=self.config['host'],
                port=self.config['port'],
                database=self.config['database'],
                user=self.config['user'],
                password=self.config['password']
            )
            
            with conn.cursor() as cursor:
                cursor.execute(query)
                deleted_count = cursor.rowcount
                conn.commit()
                
            print(f"âœ… å·²æ¸…ç†{deleted_count}æ¡æ—§æ—¥å¿—è®°å½•")
            return deleted_count
            
        except Exception as e:
            print(f"âŒ æ¸…ç†æ—¥å¿—é”™è¯¯: {e}")
            return 0
        finally:
            if 'conn' in locals():
                conn.close()
    
    def update_search_index(self) -> bool:
        """æ›´æ–°æœç´¢ç´¢å¼•"""
        print("ğŸ” æ›´æ–°æœç´¢ç´¢å¼•...")
        
        query = """
        UPDATE cases 
        SET search_vector = 
            setweight(to_tsvector('chinese', COALESCE(title, '')), 'A') ||
            setweight(to_tsvector('chinese', COALESCE(subtitle, '')), 'B') ||
            setweight(to_tsvector('chinese', COALESCE(description, '')), 'C') ||
            setweight(to_tsvector('chinese', COALESCE(summary, '')), 'C') ||
            setweight(to_tsvector('chinese', COALESCE(array_to_string(tags, ' '), '')), 'D')
        WHERE status = 'published';
        """
        
        try:
            import psycopg2
            
            conn = psycopg2.connect(
                host=self.config['host'],
                port=self.config['port'],
                database=self.config['database'],
                user=self.config['user'],
                password=self.config['password']
            )
            
            with conn.cursor() as cursor:
                cursor.execute(query)
                updated_count = cursor.rowcount
                conn.commit()
                
            print(f"âœ… å·²æ›´æ–°{updated_count}ä¸ªæ¡ˆä¾‹çš„æœç´¢ç´¢å¼•")
            return True
            
        except Exception as e:
            print(f"âŒ æ›´æ–°æœç´¢ç´¢å¼•é”™è¯¯: {e}")
            return False
        finally:
            if 'conn' in locals():
                conn.close()

def load_config_from_env() -> Dict[str, str]:
    """ä»ç¯å¢ƒå˜é‡åŠ è½½æ•°æ®åº“é…ç½®"""
    config = {}
    
    # å°è¯•ä».env.localæ–‡ä»¶è¯»å–
    env_file = '.env.local'
    if os.path.exists(env_file):
        with open(env_file, 'r') as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    if key.startswith('VITE_SUPABASE_'):
                        config[key] = value
    
    # ä»Supabase URLè§£ææ•°æ®åº“é…ç½®
    supabase_url = config.get('VITE_SUPABASE_URL', os.getenv('VITE_SUPABASE_URL', ''))
    if supabase_url:
        # è§£æSupabase URL: https://xxxxx.supabase.co
        project_id = supabase_url.replace('https://', '').replace('.supabase.co', '')
        config.update({
            'host': f'db.{project_id}.supabase.co',
            'port': '5432',
            'database': 'postgres',
            'user': 'postgres',
            'password': input("è¯·è¾“å…¥Supabaseæ•°æ®åº“å¯†ç : ")
        })
    
    return config

def main():
    parser = argparse.ArgumentParser(description='é»„åœŸé«˜åŸæ¡ˆä¾‹åº“æ•°æ®åº“ç®¡ç†å·¥å…·')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºç½‘ç«™ç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--popular', action='store_true', help='æ˜¾ç¤ºçƒ­é—¨æ¡ˆä¾‹')
    parser.add_argument('--activity', action='store_true', help='æ˜¾ç¤ºç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡')
    parser.add_argument('--ai-stats', action='store_true', help='æ˜¾ç¤ºAIä½¿ç”¨ç»Ÿè®¡')
    parser.add_argument('--backup', action='store_true', help='å¤‡ä»½æ•°æ®åº“')
    parser.add_argument('--clean-logs', type=int, metavar='DAYS', help='æ¸…ç†Nå¤©å‰çš„è®¿é—®æ—¥å¿—')
    parser.add_argument('--update-index', action='store_true', help='æ›´æ–°æœç´¢ç´¢å¼•')
    parser.add_argument('--all', action='store_true', help='æ‰§è¡Œæ‰€æœ‰ç»Ÿè®¡æŸ¥è¯¢')
    
    args = parser.parse_args()
    
    if not any(vars(args).values()):
        parser.print_help()
        return
    
    # åŠ è½½æ•°æ®åº“é…ç½®
    config = load_config_from_env()
    if not config.get('host'):
        print("âŒ é”™è¯¯: æ— æ³•è·å–æ•°æ®åº“é…ç½®")
        print("è¯·ç¡®ä¿.env.localæ–‡ä»¶ä¸­åŒ…å«VITE_SUPABASE_URLé…ç½®")
        return
    
    # åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨
    db_manager = DatabaseManager(config)
    
    try:
        if args.stats or args.all:
            db_manager.get_site_statistics()
            print()
        
        if args.popular or args.all:
            db_manager.get_popular_cases()
            print()
        
        if args.activity or args.all:
            db_manager.get_user_activity()
            print()
        
        if args.ai_stats or args.all:
            db_manager.get_ai_usage_stats()
            print()
        
        if args.backup:
            backup_file = db_manager.backup_database()
            if backup_file:
                print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶ä½ç½®: {backup_file}")
        
        if args.clean_logs:
            db_manager.clean_old_logs(args.clean_logs)
        
        if args.update_index:
            db_manager.update_search_index()
            
    except KeyboardInterrupt:
        print("\n\nâš  æ“ä½œå·²å–æ¶ˆ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
